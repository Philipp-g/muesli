{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trainCoders.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "iqpwVayyS2V-",
        "Tx0hAciOTBZe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Philipp-g/muesli/blob/master/trainCoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvGQ8caUSyn2",
        "colab_type": "text"
      },
      "source": [
        "# Init"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "priYdQc1p39B",
        "colab_type": "code",
        "outputId": "3b3ebba4-0817-4251-98b2-8822f4be8f87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import os.path\n",
        "if not os.path.exists('sim_file_sdf.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_file_sdf.h5\n",
        "if not os.path.exists('sim_file_vae.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_file_vae.h5\n",
        "if not os.path.exists('sim_file_train.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_file_train.h5\n",
        "if not os.path.exists('sim_file_test.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_file_test.h5\n",
        "if not os.path.exists('sim_no_obstacles.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_no_obstacles.h5\n",
        "if not os.path.exists('sim_no_obstacle_train.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_no_obstacle_train.h5\n",
        "if not os.path.exists('sim_no_obstacle_test.h5'):\n",
        "    !wget -c https://files:Bananensuppe@files.dd5hw.de/share/sim_no_obstacle_test.h5\n",
        "            \n",
        "!pip3 uninstall -y h5py\n",
        "!apt install --reinstall -y python3-h5py\n",
        "\n",
        "!git -C NetFlow pull || git clone https://github.com/uprestel/NetFlow.git\n",
        "!cd NetFlow && git checkout master && cd .."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling h5py-2.7.1:\n",
            "  Successfully uninstalled h5py-2.7.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 1 reinstalled, 0 to remove and 8 not upgraded.\n",
            "Need to get 631 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python3-h5py amd64 2.7.1-2 [631 kB]\n",
            "Fetched 631 kB in 1s (521 kB/s)\n",
            "(Reading database ... 131272 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-h5py_2.7.1-2_amd64.deb ...\n",
            "Unpacking python3-h5py (2.7.1-2) over (2.7.1-2) ...\n",
            "Setting up python3-h5py (2.7.1-2) ...\n",
            "Already up to date.\n",
            "Already on 'master'\n",
            "Your branch is up to date with 'origin/master'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeT_-T72pwMX",
        "colab_type": "code",
        "outputId": "8a57c61e-212d-40b2-c4d0-8db3bbb910c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "\n",
        "from NetFlow.sim_file import HDF5Dataset\n",
        "#from NetFlow.nn_custom_layers import SmallConvBlock, BigConvBlock, U_Layer\n",
        "from NetFlow.nn_loss import custom_loss\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from collections import defaultdict, deque\n",
        "import sys"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  from ._conv import register_converters as _register_converters\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1myZOwJIrlCZ",
        "colab_type": "code",
        "outputId": "fef28c96-8886-40df-f242-cecd4818818c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"using {} for computations\".format(device))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda:0 for computations\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqpwVayyS2V-",
        "colab_type": "text"
      },
      "source": [
        "# custom_layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9OQ0J0aVzSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "_________________________________________________________________________________________________\n",
        "                                                                                                 |\n",
        "Authors: * Ulrich Prestel    <Ulrich.Prestel@protonmail.com>                                     |\n",
        "         * Holger WÃ¼nsche    <Holger.o.wuensche@t-online.de>                                     |\n",
        "_________________________________________________________________________________________________|\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class SmallConvBlock(nn.Module):\n",
        "\n",
        "    CONV_KERNEL_SIZE = 3\n",
        "    CONV_STRIDE = 1\n",
        "    CONV_PADDING = 1\n",
        "    CONV_DIALATION = 1\n",
        "    CONV_GROUPS = 1\n",
        "    CONV_BIAS = True\n",
        "    CONV_ACTIVATION = nn.LeakyReLU()\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, depth = 1,\n",
        "            kernel = CONV_KERNEL_SIZE, stride = CONV_STRIDE, padding = CONV_PADDING,\n",
        "            dialation = CONV_DIALATION, groups = CONV_GROUPS, bias = CONV_BIAS,\n",
        "            activation = CONV_ACTIVATION):\n",
        "        super(SmallConvBlock, self).__init__()\n",
        "\n",
        "        self.conv_blocks = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            self.conv_blocks.append(nn.Conv2d(in_channel, out_channel, kernel,\n",
        "                stride, padding, dialation, groups, bias))\n",
        "        self.activation_function = activation\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        x = input_tensor\n",
        "\n",
        "        first = False\n",
        "        for layer in self.conv_blocks:\n",
        "            if not first:\n",
        "                x = self.activation_function(x)\n",
        "            x = layer(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class BigConvBlock(nn.Module):\n",
        "\n",
        "    CONV_KERNEL_SIZE = 3\n",
        "    CONV_STRIDE = 1\n",
        "    CONV_PADDING = 1\n",
        "    CONV_DIALATION = 1\n",
        "    CONV_GROUPS = 1\n",
        "    CONV_BIAS = True\n",
        "    CONV_ACTIVATION = nn.LeakyReLU()\n",
        "    CONV_SKIP = lambda a, b : a.add(b)\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, small_blocks, small_block_depth,\n",
        "            mode='', kernel = CONV_KERNEL_SIZE, stride = CONV_STRIDE, padding = CONV_PADDING,\n",
        "            dialation = CONV_DIALATION, groups = CONV_GROUPS, bias = CONV_BIAS,\n",
        "            activation = CONV_ACTIVATION, skip = CONV_SKIP):\n",
        "        super(BigConvBlock, self).__init__()\n",
        "\n",
        "        self.small_conv_blocks = nn.ModuleList()\n",
        "        for i in range(small_blocks):\n",
        "            self.small_conv_blocks.append(SmallConvBlock(in_channel,\n",
        "                out_channel, small_block_depth, kernel, stride,\n",
        "                padding, dialation, groups, bias))\n",
        "        self.skip_function = skip\n",
        "        \n",
        "        self.mode = mode\n",
        "        \n",
        "        if self.mode == 'up':\n",
        "            self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        elif self.mode == 'down':\n",
        "            self.downsample = nn.Conv2d(\n",
        "                in_channels=out_channel,\n",
        "                out_channels=out_channel,\n",
        "                kernel_size=3,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                dilation=1,\n",
        "                groups=1,\n",
        "                bias=True)\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        x = input_tensor\n",
        "        for layer in self.small_conv_blocks:\n",
        "            x = layer(x)\n",
        "        \n",
        "        if self.mode == 'up':\n",
        "            x = self.upsample(x)\n",
        "            input_tensor = self.upsample(input_tensor)\n",
        "            x = self.skip_function(x, input_tensor)\n",
        "        elif self.mode == 'down':\n",
        "            x = self.skip_function(x, input_tensor)\n",
        "            x = self.downsample(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class U_Layer(nn.Module):\n",
        "\n",
        "    CONV_DOWN_LAYERS = 2\n",
        "    UPSAMPLING_BILINEAR = True\n",
        "    CONV_UP_LAYERS = 2\n",
        "    CONV_KERNEL_SIZE = 3\n",
        "    CONV_STRIDE = 1\n",
        "    CONV_PADDING = 1\n",
        "    CONV_DIALATION = 1\n",
        "    CONV_GROUPS = 1\n",
        "    CONV_BIAS = True\n",
        "    CONV_ACTIVATION = nn.ReLU()\n",
        "\n",
        "    def __init__(self, in_channel, out_channel, depth = 1, hidden_layers=[],\n",
        "            conv_layers=CONV_DOWN_LAYERS, upsampling_bilinear=UPSAMPLING_BILINEAR,\n",
        "            kernel = CONV_KERNEL_SIZE, stride = CONV_STRIDE, padding = CONV_PADDING,\n",
        "            dialation = CONV_DIALATION, groups = CONV_GROUPS, bias = CONV_BIAS,\n",
        "            activation = CONV_ACTIVATION):\n",
        "        super(U_Layer, self).__init__()\n",
        "\n",
        "        self.depth = depth\n",
        "\n",
        "        self.hidden_layers = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            if i < len(hidden_layers):\n",
        "                self.hidden_layers.append(hidden_layers[i])\n",
        "\n",
        "        # down\n",
        "        self.down_blocks = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            parts = []\n",
        "            parts.append(nn.MaxPool2d(2))\n",
        "\n",
        "            for j in range(conv_layers):\n",
        "                parts.append(nn.Conv2d(in_channel, out_channel, kernel,\n",
        "                    stride, padding, dialation, groups, bias))\n",
        "                in_channel = out_channel # make size in layer consistent after first conv\n",
        "                parts.append(nn.BatchNorm2d(out_channel))\n",
        "                parts.append(activation)\n",
        "            self.down_blocks.append(nn.Sequential(*parts))\n",
        "\n",
        "        # up\n",
        "        if upsampling_bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_ch//2, in_ch//2, 2, stride=2)\n",
        "\n",
        "        self.up_blocks = nn.ModuleList()\n",
        "        for i in range(depth):\n",
        "            self.up_blocks.append(nn.Sequential(\n",
        "                nn.Conv2d(in_channel*2, out_channel, kernel, stride, padding, dialation, groups, bias),\n",
        "                nn.BatchNorm2d(out_channel),\n",
        "                activation\n",
        "            ))\n",
        "\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        x = input_tensor\n",
        "\n",
        "        connections = [None] * self.depth\n",
        "        connections[0] = input_tensor\n",
        "\n",
        "        # down pass\n",
        "        for i in range(1, self.depth):\n",
        "            connections[i] = self.down_blocks[i](connections[i-1])\n",
        "            if self.depth-1-i < len(self.hidden_layers):\n",
        "                connections[i] = self.hidden_layers[self.depth-1-i](connections[i])\n",
        "\n",
        "        # up pass\n",
        "        for i in range(self.depth-1, 1-1, -1):\n",
        "            x1 = connections[i]\n",
        "            x2 = connections[i-1]\n",
        "\n",
        "            x = self.up(x1)\n",
        "\n",
        "            diffY = x2.size()[2] - x1.size()[2]\n",
        "            diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "            x1 = F.pad(x1, (diffX // 2, diffX - diffX//2,\n",
        "                        diffY // 2, diffY - diffY//2))\n",
        "\n",
        "            x = torch.cat([x2, x1], dim=1)\n",
        "            #connections[i-1] = None\n",
        "            connections[i-1] = self.up_blocks[i](x)\n",
        "\n",
        "\n",
        "        return connections[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFZ6HGVOS93u",
        "colab_type": "text"
      },
      "source": [
        "# Netzwerk Definitionen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4NTSAzXch9a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class deep_fluid_Encoder(nn.Module):\n",
        "    def __init__(self, in_shape, n_latent=16, hidden_channels=128):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.in_shape = in_shape\n",
        "        self.n_latent = n_latent\n",
        "        \n",
        "        c,h,w = in_shape\n",
        "        \n",
        "        bigblock_count = math.ceil(math.log2(max(h,w)))-3\n",
        "        smallblock_depth = 3\n",
        "        \n",
        "        self.z_h = int(h/2**bigblock_count)\n",
        "        self.z_w = int(w/2**bigblock_count)\n",
        "        \n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Conv2d(c, hidden_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU()])\n",
        "        \n",
        "        for i in range(bigblock_count):\n",
        "            if i < bigblock_count-1:\n",
        "                self.layers.append(\n",
        "                    BigConvBlock(hidden_channels, hidden_channels, 1,\n",
        "                                 small_block_depth=smallblock_depth,\n",
        "                                 mode='down',\n",
        "                                 kernel=3,\n",
        "                                 stride=1,\n",
        "                                 padding=1,\n",
        "                                 activation=nn.LeakyReLU,\n",
        "                                 skip=lambda a, b : a.add(b))\n",
        "                )\n",
        "            else:\n",
        "                self.layers.append(\n",
        "                    BigConvBlock(hidden_channels, hidden_channels, 1,\n",
        "                                 small_block_depth=smallblock_depth,\n",
        "                                 mode='down',\n",
        "                                 kernel=3,\n",
        "                                 stride=1,\n",
        "                                 padding=1,\n",
        "                                 activation=nn.LeakyReLU,\n",
        "                                 skip=lambda a, b : a.add(b))\n",
        "                )\n",
        "\n",
        "            self.output_layers = nn.ModuleList([\n",
        "                nn.Linear(self.z_h*self.z_w*hidden_channels, n_latent)\n",
        "            ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        \n",
        "        x = x.view(x.shape[0], -1)\n",
        "        \n",
        "        for layer in self.output_layers:\n",
        "            x = layer(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug24G-IWgR4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class deep_fluid_Decoder(nn.Module):\n",
        "    def __init__(self, out_shape, n_latent=16, hidden_channels=128):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.out_shape = out_shape\n",
        "        self.n_latent = n_latent\n",
        "        \n",
        "        c,h,w = out_shape\n",
        "        \n",
        "        bigblock_count = math.ceil(math.log2(max(h,w)))-3\n",
        "        smallblock_depth = 3\n",
        "        \n",
        "        self.z_h = int(h/2**bigblock_count)\n",
        "        self.z_w = int(w/2**bigblock_count)\n",
        "        \n",
        "        self.input_layers = nn.ModuleList([\n",
        "            nn.Linear(n_latent, self.z_h*self.z_w*c)\n",
        "        ])\n",
        "        \n",
        "        self.layers = nn.ModuleList([\n",
        "            nn.Conv2d(c, hidden_channels, kernel_size=3, stride=1, padding=1),\n",
        "            nn.LeakyReLU()])\n",
        "        \n",
        "        for i in range(bigblock_count):\n",
        "            if i < bigblock_count-1:\n",
        "                self.layers.append(\n",
        "                    BigConvBlock(hidden_channels, hidden_channels, 1,\n",
        "                                 small_block_depth=smallblock_depth,\n",
        "                                 mode='up',\n",
        "                                 kernel=3,\n",
        "                                 stride=1,\n",
        "                                 padding=1,\n",
        "                                 activation=nn.LeakyReLU,\n",
        "                                 skip=lambda a, b : a.add(b))\n",
        "                )\n",
        "            else:\n",
        "                self.layers.append(\n",
        "                    BigConvBlock(hidden_channels, hidden_channels, 1,\n",
        "                                 small_block_depth=smallblock_depth,\n",
        "                                 mode='up',\n",
        "                                 kernel=3,\n",
        "                                 stride=1,\n",
        "                                 padding=1,\n",
        "                                 activation=nn.LeakyReLU,\n",
        "                                 skip=lambda a, b : a.add(b))\n",
        "                )\n",
        "\n",
        "        self.layers.append(nn.Conv2d(hidden_channels, c, kernel_size=3, stride=1, padding=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.input_layers:\n",
        "            x = layer(x)\n",
        "        \n",
        "        x = x.view(x.shape[0], self.out_shape[0], self.z_h, self.z_w)\n",
        "            \n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JpV2gWf3SJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdvanceNet(nn.Module):\n",
        "    def __init__(self, n_latent=16):\n",
        "        super(AdvanceNet, self).__init__()\n",
        "        self.n_latent = n_latent\n",
        "        self.arch = nn.Sequential(\n",
        "            nn.Linear(n_latent, 1024),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ELU(),\n",
        "            nn.Linear(512, n_latent),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        dz = self.arch(z)\n",
        "        return dz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIt2eEuwqOGt",
        "colab_type": "text"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqbXd8E6qPrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import math\n",
        "\n",
        "# loss-types\n",
        "#  single-frame losses:\n",
        "#   reconstruction_loss: loss of the first Frame in the input_tensor\n",
        "#   sdf_loss: loss of the first Frame in the input_tensor using only the sdf-channel\n",
        "#   single_frame_loss: loss of the first Frame returned by the Network (second frame in tensor)\n",
        "#   single_frame_change_loss: loss for the change between the first 2 frames (first is given by the dataset, second is from the network)\n",
        "#   masked_frane_loss: [experimental] sum of the entries, that should be 0 (used to minimize affect of common values in many frames)\n",
        "#\n",
        "#  multi-frame losses (use running factors to priorize early/late frames (<1 for early frames; >1 for later frames; =1 for equal weights):\n",
        "#   following_frame_loss: single_frame_loss applied on all additional frames\n",
        "#   following_frame_change_loss: single_frame_change_loss for all additional frames\n",
        "#   following_masked_frame_loss: masked_frane_loss for all additional frames\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class custom_loss(nn.modules.loss._Loss):\n",
        "    def __init__(self, reconstruction_factor=1, sdf_factor=1, sdf_penalty=10, sdf_position=0, \n",
        "            single_frame_factor=1, single_frame_change_factor=1,\n",
        "            masked_frame_factor=0, following_frame_factor=1,\n",
        "            following_frame_change_factor=1, following_masked_frame_factor=0,\n",
        "            following_frame_running_factor=1,\n",
        "            following_frame_change_running_factor=1, channel_factors = 1,\n",
        "            kl_factor = 1, latent_factor = 1, loss_update_factors=lambda factors, loss : factors,\n",
        "            single_frame_loss_fn=nn.MSELoss(), bitmap_loss_fn=nn.BCELoss(),\n",
        "            latent_loss_fn=nn.MSELoss(), eps=1e-14):\n",
        "        super(custom_loss, self).__init__(None, None, 'mean')\n",
        "\n",
        "        self.factors = {\n",
        "            \"reconstruction_factor\": reconstruction_factor,\n",
        "            \"sdf_factor\": sdf_factor,\n",
        "            \"sdf_penalty\": sdf_penalty,\n",
        "\n",
        "            \"single_frame_factor\": single_frame_factor,\n",
        "            \"single_frame_change_factor\": single_frame_change_factor,\n",
        "            \"masked_frame_factor\": masked_frame_factor,\n",
        "\n",
        "            \"following_frame_factor\": following_frame_factor,\n",
        "            \"following_masked_frame_factor\": following_masked_frame_factor,\n",
        "            \"following_frame_running_factor\": following_frame_running_factor,\n",
        "            \"following_frame_change_factor\": following_frame_change_factor,\n",
        "            \"following_frame_change_running_factor\": following_frame_change_running_factor,\n",
        "\n",
        "            \"kl_factor\": kl_factor,\n",
        "            \"latent_factor\": latent_factor,\n",
        "        }\n",
        "\n",
        "\n",
        "        if type(channel_factors) == tuple or type(channel_factors) == list:\n",
        "            self.factors['channel_factors'] = channel_factors\n",
        "        else:\n",
        "            self.factors['channel_factors'] = (channel_factors,)\n",
        "\n",
        "        self.sdf_position = sdf_position\n",
        "\n",
        "        self.loss_update_factors = loss_update_factors\n",
        "\n",
        "        self.single_frame_loss_fn = single_frame_loss_fn\n",
        "        self.bitmap_loss_fn = bitmap_loss_fn\n",
        "        self.latent_loss_fn = latent_loss_fn\n",
        "\n",
        "        self.eps = eps\n",
        "\n",
        "    def apply_with_channel_factor(self, input, target, loss_fn):\n",
        "        loss = 0\n",
        "        factor_sum = 0\n",
        "        for i in range(input.shape[1]):\n",
        "            factor = 0\n",
        "            if i < len(self.factors['channel_factors']):\n",
        "                factor = self.factors['channel_factors'][i]\n",
        "            else:\n",
        "                factor = self.factors['channel_factors'][-1]\n",
        "            factor_sum += factor\n",
        "            loss += factor * loss_fn(input[:,i], target[:,i])\n",
        "\n",
        "        if factor_sum > 0:\n",
        "            loss /= factor_sum\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def reconstruction_loss(self, input, target):\n",
        "        reconstruction_loss = self.apply_with_channel_factor(input[:,range(input.shape[1]),0], target[:,range(target.shape[1]),0], self.single_frame_loss_fn)\n",
        "\n",
        "        return reconstruction_loss\n",
        "\n",
        "    def sdf_loss(self, input, target, position):\n",
        "        sdf_loss = self.single_frame_loss_fn(input[:,position,0], target[:,position,0])\n",
        "\n",
        "        input_bitmap = (input[:,range(input.shape[1]),0] <= 0).float()\n",
        "        target_bitmap = (target[:,range(input.shape[1]),0] <= 0).float()\n",
        "        if self.bitmap_loss_fn(input_bitmap, target_bitmap) > 0:\n",
        "            sdf_loss *= self.factors['sdf_penalty']\n",
        "\n",
        "        return sdf_loss\n",
        "\n",
        "    def simple_frame_loss(self, input, target):\n",
        "        single_frame_loss = self.apply_with_channel_factor(input[:,range(input.shape[1]),1], target[:,range(target.shape[1]),1], self.single_frame_loss_fn)\n",
        "\n",
        "        # compute following frame loss\n",
        "        following_frame_loss = 0\n",
        "        running_factor = self.factors['following_frame_running_factor']\n",
        "        for i in range(2, target.shape[2]):\n",
        "            following_frame_loss += running_factor * self.apply_with_channel_factor(input[:,range(input.shape[1]),i], target[:,range(target.shape[1]),i], self.single_frame_loss_fn)\n",
        "            running_factor *= running_factor\n",
        "        # normalize over number of frames\n",
        "        if target.shape[2]-2 > 0:\n",
        "            following_frame_loss /= target.shape[2]-2\n",
        "\n",
        "        return single_frame_loss, following_frame_loss\n",
        "\n",
        "    def masked_frame_loss(self, input, target):\n",
        "        # find all datapoints with (almost) no values\n",
        "        mask = ((target < self.eps)*(target > -self.eps)).float()\n",
        "        masked_input = torch.abs(input*mask)\n",
        "\n",
        "        # sum all entries in mask\n",
        "        masked_frame_loss = self.apply_with_channel_factor(\n",
        "                masked_input[:,range(input.shape[1]),1],\n",
        "                target[:,range(target.shape[1]),1], lambda a, b: torch.sum(a))\n",
        "\n",
        "        # summ entries for following frames\n",
        "        following_masked_frame_loss = 0\n",
        "        running_factor = self.factors['following_frame_running_factor']\n",
        "        for i in range(2, target.shape[2]):\n",
        "            following_masked_frame_loss += running_factor * self.apply_with_channel_factor(\n",
        "                    masked_input[:,range(input.shape[1]),i],\n",
        "                    target[:,range(target.shape[1]),i],\n",
        "                    lambda a, b: torch.sum(a))\n",
        "            running_factor *= running_factor\n",
        "        # normalize over number of frames\n",
        "        if target.shape[2]-2 > 0:\n",
        "            following_masked_frame_loss /= target.shape[2]-2\n",
        "\n",
        "        return masked_frame_loss, following_masked_frame_loss\n",
        "\n",
        "    def simple_change_loss(self, input, target):\n",
        "        # changes in simulation data\n",
        "        d_target = target[:,range(target.shape[1]),1:] - target[:,range(target.shape[1]),0:-1]\n",
        "\n",
        "        # changes in predicted data\n",
        "        d_input = input[:,range(input.shape[1]),1:] - input[:,range(input.shape[1]),0:-1]\n",
        "\n",
        "        # compute single frame loss\n",
        "        single_frame_change_loss = self.apply_with_channel_factor(d_input[:,range(d_input.shape[1]),0], d_target[:,range(d_target.shape[1]),0], self.single_frame_loss_fn)\n",
        "\n",
        "        following_frame_change_loss = 0\n",
        "        running_factor = self.factors['following_frame_change_running_factor']\n",
        "        for i in range(1, d_target.shape[2]):\n",
        "            following_frame_change_loss += running_factor * self.apply_with_channel_factor(d_input[:,range(d_input.shape[1]),i], d_target[:,range(d_target.shape[1]),i], self.single_frame_loss_fn)\n",
        "            running_factor *= running_factor\n",
        "        # normalize over number of frames\n",
        "        if d_target.shape[2]-1 > 0:\n",
        "            following_frame_change_loss /= d_target.shape[2]-1\n",
        "\n",
        "        return single_frame_change_loss, following_frame_change_loss\n",
        "\n",
        "    def kl_loss(self, mean, logvar):\n",
        "        a = torch.exp(logvar) + mean**2 - 1. - logvar\n",
        "        b = torch.sum(a, 1)\n",
        "\n",
        "        kl_loss = torch.mean(0.5 * b)\n",
        "\n",
        "        return kl_loss\n",
        "    \n",
        "    def latent_loss(self, in_latents, target_latents):\n",
        "        latent_loss = 0\n",
        "        \n",
        "        for i in range(target_latents.shape[1]):\n",
        "            latent_loss += self.latent_loss_fn(in_latents[:,i], target_latents[:,i])\n",
        "            \n",
        "        return latent_loss\n",
        "\n",
        "    def forward(self, input, target, in_latents=None, target_latents=None, mean=None, logvar=None):\n",
        "        reconstruction_loss = self.reconstruction_loss(input,target)\n",
        "        sdf_loss = self.sdf_loss(input, target, self.sdf_position)\n",
        "        single_frame_loss, following_frame_loss = self.simple_frame_loss(input, target)\n",
        "        single_frame_change_loss, following_frame_change_loss = self.simple_change_loss(input, target)\n",
        "        masked_frame_loss, following_masked_frame_loss = self.masked_frame_loss(input, target)\n",
        "        kl_loss = 0\n",
        "        if not (mean is None and logvar is None):\n",
        "            kl_loss = self.kl_loss(mean, logvar)\n",
        "        latent_loss = 0\n",
        "        if not (in_latents is None and target_latents is None):\n",
        "            latent_loss = self.latent_loss(in_latents, target_latents)\n",
        "\n",
        "            \n",
        "        loss = 0\n",
        "        loss += self.factors['reconstruction_factor'] * reconstruction_loss\n",
        "        loss += self.factors['sdf_factor'] * sdf_loss\n",
        "        loss += self.factors['single_frame_factor'] * single_frame_loss\n",
        "        loss += self.factors['single_frame_change_factor'] * single_frame_change_loss\n",
        "        loss += self.factors['masked_frame_factor'] * masked_frame_loss\n",
        "        loss += self.factors['following_frame_factor'] * following_frame_loss\n",
        "        loss += self.factors['following_frame_change_factor'] * following_frame_change_loss\n",
        "        loss += self.factors['following_masked_frame_factor'] * following_masked_frame_loss\n",
        "        if not (mean is None and logvar is None):\n",
        "            loss += self.factors['kl_factor'] * kl_loss\n",
        "        if not (in_latents is None and target_latents is None):\n",
        "            loss += self.factors['latent_factor'] * latent_loss\n",
        "            \n",
        "        self.last_loss_components = {\n",
        "            \"reconstruction_loss\": reconstruction_loss,\n",
        "            \"sdf_loss\": sdf_loss,\n",
        "            \"single_frame_loss\": single_frame_loss,\n",
        "            \"single_frame_change_loss\": single_frame_change_loss,\n",
        "            \"masked_frame_loss\": masked_frame_loss,\n",
        "            \"following_frame_loss\": following_frame_loss,\n",
        "            \"following_frame_change_loss\": following_frame_change_loss,\n",
        "            \"following_masked_frame_loss\": following_masked_frame_loss,\n",
        "            \"kl_loss\": kl_loss,\n",
        "            \"latent_loss\": latent_loss\n",
        "        }\n",
        "\n",
        "        for loss_name, value in self.last_loss_components.items():\n",
        "            if not math.isfinite(value):\n",
        "                raise RuntimeError(\"{} is {}! (input sum: {}, target sum: {}, mean sum: {}, logvar sum: {})\".format(loss_name, float(value), float(torch.sum(input)), float(torch.sum(target)), float(torch.sum(mean)), float(torch.sum(logvar))))\n",
        "\n",
        "        with torch.set_grad_enabled(False):\n",
        "            self.factors = self.loss_update_factors(self.factors, self.last_loss_components)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq-_ALLZTGIK",
        "colab_type": "text"
      },
      "source": [
        "# helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjRd8bTxG8Sn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def work_batch(encoder, advance, decoder, input, simulation_channels=2, n_latent=16, consecutive_frames=2):\n",
        "    # prepare tensor for model-results\n",
        "    recons = torch.zeros((input.shape[0],\n",
        "                            simulation_channels,\n",
        "                            consecutive_frames,\n",
        "                            input.shape[2],\n",
        "                            input.shape[3]), dtype=torch.float, device=input.device)\n",
        "    latents = torch.zeros((input.shape[0],\n",
        "                            consecutive_frames,\n",
        "                            n_latent), dtype=torch.float, device=input.device)\n",
        "    \n",
        "    z =  encoder(input)\n",
        "    \n",
        "    latents[:,0] = z\n",
        "    recons[:,range(simulation_channels),0] = decoder(z)\n",
        "    \n",
        "    for i in range(consecutive_frames-1):\n",
        "        dz = advance(z)\n",
        "        z = z+dz\n",
        "        \n",
        "        latents[:,0] = z\n",
        "        recons[:,range(simulation_channels),i+1] = decoder(z)\n",
        "    \n",
        "    return recons, latents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH-Ct_komqjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_batch(encoder, target, n_latent=16, consecutive_frames=2):\n",
        "    # prepare tensor for model-results\n",
        "    latents = torch.zeros((target.shape[0],\n",
        "                            consecutive_frames,\n",
        "                            n_latent), dtype=torch.float, device=target.device)\n",
        "    \n",
        "    for i in range(consecutive_frames):\n",
        "        z =  encoder(target[:,range(target.shape[1]),i])\n",
        "        latents[:,i] = z\n",
        "    \n",
        "    return latents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw-4FnyKVzHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(encoder, advance, decoder, train_loader, loss_fn, num_epochs=5, in_channel=2, n_latent=16, learning_rate=1e-3):\n",
        "    torch.manual_seed(42)\n",
        "    \n",
        "    optimizer = torch.optim.Adam(list(encoder.parameters())+list(advance.parameters())+list(decoder.parameters()),\n",
        "                                 lr=learning_rate,\n",
        "                                 weight_decay=1e-5)\n",
        "\n",
        "    losses = defaultdict(list)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        loss_buffer = []\n",
        "        for in_tensor, out_tensor in tqdm(train_loader, position=0, desc=\"epoch {}\".format(epoch+1), leave=True):\n",
        "            in_tensor = in_tensor.to(device)\n",
        "            out_tensor = out_tensor.to(device)\n",
        "            \n",
        "            consecutive_frames = out_tensor.shape[2]\n",
        "                                 \n",
        "            recons, latents = work_batch(encoder, advance, decoder, in_tensor, in_channel, n_latent, consecutive_frames)\n",
        "            target_latents = encode_batch(encoder, out_tensor, n_latent, consecutive_frames)\n",
        "            \n",
        "            loss = loss_fn(recons, out_tensor, latents, target_latents)\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            with torch.set_grad_enabled(False):\n",
        "                loss_buffer.append(float(loss))\n",
        "\n",
        "                for key, data in loss_fn.last_loss_components.items():\n",
        "                    losses[key] += [float(data)]\n",
        "\n",
        "        tqdm.write('Epoch:{}, Loss:{:.4f}'.format(epoch+1, sum(loss_buffer)/len(loss_buffer)))\n",
        "    return losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPrds2cSsIq7",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrhdi0pKrbjR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make sure to adapt to your files\n",
        "train_file = \"sim_no_obstacle_train.h5\"\n",
        "test_file  = \"sim_no_obstacle_test.h5\"\n",
        "\n",
        "\n",
        "def transform(data):\n",
        "    #return torch.FloatTensor([data['density'][0], data['pressure'][0], data['velocity_x'][0], data['velocity_y'][0]])\n",
        "    #return torch.FloatTensor([data['density'][0]]), torch.FloatTensor([data['density']])\n",
        "    #return torch.FloatTensor([data['sdf_obstacles'], data['velocity_x'][0], data['velocity_y'][0]]), \\\n",
        "    #        torch.FloatTensor([np.stack((data['sdf_obstacles'],)*len(data['velocity_x'])), data['velocity_x'], data['velocity_y']])\n",
        "    return torch.FloatTensor([data['velocity_x'][0], data['velocity_y'][0]]), \\\n",
        "            torch.FloatTensor([data['velocity_x'], data['velocity_y']])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaxWZ2mQ5g0o",
        "colab_type": "code",
        "outputId": "d10a204f-c4e6-45e1-e018-bf06f31430fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tqdm.write(\"building models\")\n",
        "\n",
        "n_latent = 16\n",
        "\n",
        "encoder = deep_fluid_Encoder((2, 64, 64), n_latent=n_latent, hidden_channels=128).to(device)\n",
        "advance = AdvanceNet(n_latent=n_latent).to(device)\n",
        "decoder = deep_fluid_Decoder((2, 64, 64), n_latent=n_latent, hidden_channels=128).to(device)\n",
        "\n",
        "losses = defaultdict(list)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 6:  47%|âââââ     | 17/36 [1:35:54<00:39,  2.06s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "building models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhDfFqlUu0Ge",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "16f61283-b2f9-4c3a-f128-820dcff08b61"
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(encoder, input_size=(2, 64, 64))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 64, 64]           2,432\n",
            "         LeakyReLU-2          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-3          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-4          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-5          [-1, 128, 64, 64]               0\n",
            "            Conv2d-6          [-1, 128, 64, 64]         147,584\n",
            "         LeakyReLU-7          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-8          [-1, 128, 64, 64]               0\n",
            "         LeakyReLU-9          [-1, 128, 64, 64]               0\n",
            "           Conv2d-10          [-1, 128, 64, 64]         147,584\n",
            "        LeakyReLU-11          [-1, 128, 64, 64]               0\n",
            "        LeakyReLU-12          [-1, 128, 64, 64]               0\n",
            "        LeakyReLU-13          [-1, 128, 64, 64]               0\n",
            "           Conv2d-14          [-1, 128, 64, 64]         147,584\n",
            "   SmallConvBlock-15          [-1, 128, 64, 64]               0\n",
            "           Conv2d-16          [-1, 128, 32, 32]         147,584\n",
            "     BigConvBlock-17          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-18          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-19          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-20          [-1, 128, 32, 32]               0\n",
            "           Conv2d-21          [-1, 128, 32, 32]         147,584\n",
            "        LeakyReLU-22          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-23          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-24          [-1, 128, 32, 32]               0\n",
            "           Conv2d-25          [-1, 128, 32, 32]         147,584\n",
            "        LeakyReLU-26          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-27          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-28          [-1, 128, 32, 32]               0\n",
            "           Conv2d-29          [-1, 128, 32, 32]         147,584\n",
            "   SmallConvBlock-30          [-1, 128, 32, 32]               0\n",
            "           Conv2d-31          [-1, 128, 16, 16]         147,584\n",
            "     BigConvBlock-32          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-33          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-34          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-35          [-1, 128, 16, 16]               0\n",
            "           Conv2d-36          [-1, 128, 16, 16]         147,584\n",
            "        LeakyReLU-37          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-38          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-39          [-1, 128, 16, 16]               0\n",
            "           Conv2d-40          [-1, 128, 16, 16]         147,584\n",
            "        LeakyReLU-41          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-42          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-43          [-1, 128, 16, 16]               0\n",
            "           Conv2d-44          [-1, 128, 16, 16]         147,584\n",
            "   SmallConvBlock-45          [-1, 128, 16, 16]               0\n",
            "           Conv2d-46            [-1, 128, 8, 8]         147,584\n",
            "     BigConvBlock-47            [-1, 128, 8, 8]               0\n",
            "           Linear-48                   [-1, 16]         131,088\n",
            "================================================================\n",
            "Total params: 1,904,528\n",
            "Trainable params: 1,904,528\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 78.88\n",
            "Params size (MB): 7.27\n",
            "Estimated Total Size (MB): 86.17\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Nm3mvMzx8S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "787fc017-b773-43bd-a7be-64d23e77544f"
      },
      "source": [
        "summary(advance, input_size=(16,))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 1024]          17,408\n",
            "               ELU-2                 [-1, 1024]               0\n",
            "            Linear-3                  [-1, 512]         524,800\n",
            "               ELU-4                  [-1, 512]               0\n",
            "            Linear-5                   [-1, 16]           8,208\n",
            "================================================================\n",
            "Total params: 550,416\n",
            "Trainable params: 550,416\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.02\n",
            "Params size (MB): 2.10\n",
            "Estimated Total Size (MB): 2.12\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYXV9mYVz0KE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8037fe25-d1d1-40cc-c681-66d86739e83e"
      },
      "source": [
        "summary(decoder, input_size=(16,))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 128]           2,176\n",
            "            Conv2d-2            [-1, 128, 8, 8]           2,432\n",
            "         LeakyReLU-3            [-1, 128, 8, 8]               0\n",
            "         LeakyReLU-4            [-1, 128, 8, 8]               0\n",
            "         LeakyReLU-5            [-1, 128, 8, 8]               0\n",
            "         LeakyReLU-6            [-1, 128, 8, 8]               0\n",
            "            Conv2d-7            [-1, 128, 8, 8]         147,584\n",
            "         LeakyReLU-8            [-1, 128, 8, 8]               0\n",
            "         LeakyReLU-9            [-1, 128, 8, 8]               0\n",
            "        LeakyReLU-10            [-1, 128, 8, 8]               0\n",
            "           Conv2d-11            [-1, 128, 8, 8]         147,584\n",
            "        LeakyReLU-12            [-1, 128, 8, 8]               0\n",
            "        LeakyReLU-13            [-1, 128, 8, 8]               0\n",
            "        LeakyReLU-14            [-1, 128, 8, 8]               0\n",
            "           Conv2d-15            [-1, 128, 8, 8]         147,584\n",
            "   SmallConvBlock-16            [-1, 128, 8, 8]               0\n",
            "         Upsample-17          [-1, 128, 16, 16]               0\n",
            "         Upsample-18          [-1, 128, 16, 16]               0\n",
            "     BigConvBlock-19          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-20          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-21          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-22          [-1, 128, 16, 16]               0\n",
            "           Conv2d-23          [-1, 128, 16, 16]         147,584\n",
            "        LeakyReLU-24          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-25          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-26          [-1, 128, 16, 16]               0\n",
            "           Conv2d-27          [-1, 128, 16, 16]         147,584\n",
            "        LeakyReLU-28          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-29          [-1, 128, 16, 16]               0\n",
            "        LeakyReLU-30          [-1, 128, 16, 16]               0\n",
            "           Conv2d-31          [-1, 128, 16, 16]         147,584\n",
            "   SmallConvBlock-32          [-1, 128, 16, 16]               0\n",
            "         Upsample-33          [-1, 128, 32, 32]               0\n",
            "         Upsample-34          [-1, 128, 32, 32]               0\n",
            "     BigConvBlock-35          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-36          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-37          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-38          [-1, 128, 32, 32]               0\n",
            "           Conv2d-39          [-1, 128, 32, 32]         147,584\n",
            "        LeakyReLU-40          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-41          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-42          [-1, 128, 32, 32]               0\n",
            "           Conv2d-43          [-1, 128, 32, 32]         147,584\n",
            "        LeakyReLU-44          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-45          [-1, 128, 32, 32]               0\n",
            "        LeakyReLU-46          [-1, 128, 32, 32]               0\n",
            "           Conv2d-47          [-1, 128, 32, 32]         147,584\n",
            "   SmallConvBlock-48          [-1, 128, 32, 32]               0\n",
            "         Upsample-49          [-1, 128, 64, 64]               0\n",
            "         Upsample-50          [-1, 128, 64, 64]               0\n",
            "     BigConvBlock-51          [-1, 128, 64, 64]               0\n",
            "           Conv2d-52            [-1, 2, 64, 64]           2,306\n",
            "================================================================\n",
            "Total params: 1,335,170\n",
            "Trainable params: 1,335,170\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 33.00\n",
            "Params size (MB): 5.09\n",
            "Estimated Total Size (MB): 38.09\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hElG6jWuD_hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_factors(factors, loss):\n",
        "    return factors\n",
        "\n",
        "    factors['single_frame_factor'] = 0\n",
        "    factors['single_frame_change_factor'] = 0\n",
        "    factors['following_frame_factor'] = 0\n",
        "    factors['following_frame_change_factor'] = 0\n",
        "    factors['kl_factor'] = 0\n",
        "    \n",
        "    factors['reconstruction_factor'] = max(1, min(100, loss['reconstruction_loss']/0.005))\n",
        "    \n",
        "    if loss['reconstruction_loss'] > 0.01 :\n",
        "        return factors\n",
        "    \n",
        "    factors['single_frame_factor'] = max(1, min(100, loss['single_frame_loss']/0.005))\n",
        "    factors['single_frame_change_factor'] = max(1, min(factors['single_frame_factor']/2, loss['single_frame_change_loss']/0.005))\n",
        "    \n",
        "    if loss['single_frame_loss'] > 0.1:\n",
        "        return factors\n",
        "    \n",
        "    factors['following_frame_factor'] = max(1, min(100, loss['following_frame_loss']/0.005))\n",
        "    factors['following_frame_change_factor'] = max(1, min(factors['following_frame_factor']/2, loss['following_frame_change_loss']/0.005))\n",
        "    \n",
        "    if loss['following_frame_loss'] > 0.1:\n",
        "        return factors\n",
        "    \n",
        "    factors['kl_factor'] = max(1, min(100, loss['kl_loss']/0.1))\n",
        "    \n",
        "    return factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjCmBagNTLF_",
        "colab_type": "text"
      },
      "source": [
        "# Spielwiese :>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk1lCk2afW89",
        "colab_type": "code",
        "outputId": "f4b9e0c2-d04e-4d43-9642-2273759d65a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "number_of_frames=10\n",
        "\n",
        "# trainings setting, batchsize decreases fast with consecutive_frames\n",
        "epochs = 10\n",
        "train_batch_size = 5\n",
        "\n",
        "loss_fn = custom_loss(\n",
        "    reconstruction_factor=10,\n",
        "    sdf_factor=0,\n",
        "    sdf_penalty=20,\n",
        "    sdf_position=0,\n",
        "    single_frame_factor=0,\n",
        "    single_frame_change_factor=0,\n",
        "    masked_frame_factor=0,\n",
        "    following_frame_factor=0,\n",
        "    following_frame_change_factor=0,\n",
        "    following_masked_frame_factor=0,\n",
        "    following_frame_running_factor=1,\n",
        "    following_frame_change_running_factor=1,\n",
        "    channel_factors=1,\n",
        "    kl_factor=0,\n",
        "    latent_factor=1,\n",
        "    loss_update_factors=update_factors\n",
        ")\n",
        "\n",
        "train_dataset = HDF5Dataset(train_file, 'r', return_transform=transform, consecutive_frames=number_of_frames+1, only=\"sim 005\")\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size,\n",
        "                                      shuffle=True,\n",
        "                                      num_workers=1)\n",
        "\n",
        "losses_ = train(encoder, advance, decoder, train_loader, loss_fn, num_epochs=epochs, in_channel=2, n_latent=16, learning_rate=1e-3)\n",
        "\n",
        "for key, data in losses_.items():\n",
        "    losses[key] += data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1: 100%|ââââââââââ| 38/38 [00:42<00:00,  1.04s/it]\n",
            "epoch 2:   0%|          | 0/38 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, Loss:3.2824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2: 100%|ââââââââââ| 38/38 [00:42<00:00,  1.04s/it]\n",
            "epoch 3:   0%|          | 0/38 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:2, Loss:0.6704\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3: 100%|ââââââââââ| 38/38 [00:42<00:00,  1.04s/it]\n",
            "epoch 4:   0%|          | 0/38 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:3, Loss:0.4232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 4: 100%|ââââââââââ| 38/38 [00:42<00:00,  1.04s/it]\n",
            "epoch 5:   0%|          | 0/38 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:4, Loss:0.2995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 5: 100%|ââââââââââ| 38/38 [00:41<00:00,  1.04s/it]\n",
            "epoch 6:   0%|          | 0/38 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch:5, Loss:0.2733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 6:  39%|ââââ      | 15/38 [00:16<00:25,  1.10s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYMlIIzb4g6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn.factors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvCy2TwnZ2ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_X = 1\n",
        "NUM_Y = 1\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "fig = plt.figure(figsize=(7*NUM_X,5*NUM_Y))\n",
        "\n",
        "from scipy.ndimage.filters import gaussian_filter1d\n",
        "\n",
        "subfig = plt.subplot(NUM_Y, NUM_X, 1)\n",
        "subfig.set_title(\"loss components\")\n",
        "subfig.set_xlabel(\"number of batches\")\n",
        "subfig.set_ylabel(\"loss\")\n",
        "#subfig.set_yscale(\"log\")\n",
        "subfig.set_ylim([0,1])\n",
        "\n",
        "for label_name, values in losses.items():\n",
        "    linestyle = '-'\n",
        "    subfig.plot(gaussian_filter1d(values, sigma=20), linestyle=linestyle, label=\"{} ({:.4f})\".format(label_name, values[-1]))\n",
        "    #subfig.plot(values, linestyle=linestyle, label=\"{} ({:.4f})\".format(label_name, values[-1]))\n",
        "\n",
        "# sort legend to match importance at the end\n",
        "handles, labels = subfig.get_legend_handles_labels()\n",
        "# sort both labels and handles by labels\n",
        "labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: losses[t[0].split()[0]][-1], reverse=True))\n",
        "\n",
        "subfig.legend(handles, labels, bbox_to_anchor=(1.04,1), loc=\"upper left\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwCOc-xfk4DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_frames =50\n",
        "number_of_simulations = 5\n",
        "plot_skip = 5\n",
        "\n",
        "test_dataset = HDF5Dataset(train_file, 'r', return_transform=transform, consecutive_frames=number_of_frames+1, only='sim 005')\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=number_of_simulations,\n",
        "                                      shuffle=True,\n",
        "                                      num_workers=1)\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "    input_tensor, output_tensor = next(iter(test_loader))\n",
        "\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    output, latents = work_batch(encoder, advance, decoder, input_tensor, 2, n_latent, number_of_frames+1)\n",
        "\n",
        "output_tensor = output_tensor.numpy()\n",
        "output = output.cpu().numpy()\n",
        "\n",
        "num_x = number_of_simulations*2\n",
        "num_y = math.ceil((number_of_frames+1)/plot_skip)\n",
        "\n",
        "plt.figure(figsize=(2*num_x, 2*num_y))\n",
        "\n",
        "def plot_data(data, frame):\n",
        "    sdf = -1\n",
        "    vel_x = 0\n",
        "    vel_y = 1\n",
        "    \n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "    \n",
        "    transparent = np.array([0/256, 0/256, 0/256, 0])\n",
        "    black = np.array([0/256, 0/256, 0/256, 1])\n",
        "\n",
        "    obstacle_cm = LinearSegmentedColormap.from_list('obstacles', [transparent, black], N=2)\n",
        "    \n",
        "    plt.imshow(np.sqrt(np.square(data[vel_x][frame])+np.square(data[vel_y][frame])).squeeze(), origin='lower', cmap='jet', alpha=0.9)\n",
        "    if sdf != -1:\n",
        "        plt.imshow((data[sdf][frame] <=0).squeeze(), origin='lower', cmap=obstacle_cm)\n",
        "\n",
        "for simulation in range(number_of_simulations):\n",
        "    for frame in range(0, number_of_frames+1, plot_skip):\n",
        "        # plot target\n",
        "        plt.subplot(num_y, num_x, frame/plot_skip*num_x + simulation*2+1)\n",
        "        plot_data(output_tensor[simulation], frame)\n",
        "\n",
        "        # plot output\n",
        "        plt.subplot(num_y, num_x, frame/plot_skip*num_x + simulation*2+1 +1)\n",
        "        plot_data(output[simulation], frame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hng7_CMTVC6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_of_frames =100\n",
        "number_of_simulations = 5\n",
        "plot_skip = 5\n",
        "\n",
        "test_dataset = HDF5Dataset(train_file, 'r', return_transform=transform, consecutive_frames=1, only='sim 005')\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=number_of_simulations,\n",
        "                                      shuffle=True,\n",
        "                                      num_workers=1)\n",
        "\n",
        "with torch.set_grad_enabled(False):\n",
        "    input_tensor, output_tensor = next(iter(test_loader))\n",
        "\n",
        "    input_tensor = input_tensor.to(device)\n",
        "\n",
        "    output, latents = work_batch(encoder, advance, decoder, input_tensor, 2, n_latent, number_of_frames+1)\n",
        "\n",
        "output = output.cpu().numpy()\n",
        "\n",
        "num_x = number_of_simulations\n",
        "num_y = math.ceil((number_of_frames+1)/plot_skip)\n",
        "\n",
        "plt.figure(figsize=(2*num_x, 2*num_y))\n",
        "\n",
        "def plot_data(data, frame):\n",
        "    sdf = -1\n",
        "    vel_x = 0\n",
        "    vel_y = 1\n",
        "    \n",
        "    from matplotlib.colors import LinearSegmentedColormap\n",
        "    \n",
        "    transparent = np.array([0/256, 0/256, 0/256, 0])\n",
        "    black = np.array([0/256, 0/256, 0/256, 1])\n",
        "\n",
        "    obstacle_cm = LinearSegmentedColormap.from_list('obstacles', [transparent, black], N=2)\n",
        "    \n",
        "    plt.imshow(np.sqrt(np.square(data[vel_x][frame])+np.square(data[vel_y][frame])).squeeze(), origin='lower', cmap='jet', alpha=0.9)\n",
        "    if sdf != -1:\n",
        "        plt.imshow((data[sdf][frame] <=0).squeeze(), origin='lower', cmap=obstacle_cm)\n",
        "\n",
        "for simulation in range(number_of_simulations):\n",
        "    for frame in range(0, number_of_frames+1, plot_skip):\n",
        "        # plot output\n",
        "        plt.subplot(num_y, num_x, frame/plot_skip*num_x + simulation+1)\n",
        "        plot_data(output[simulation], frame)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}